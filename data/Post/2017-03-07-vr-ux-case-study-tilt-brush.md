---
title: "VR UX Case Study: Tilt Brush"
slug: vr-ux-case-study-tilt-brush
author: kenton
category: design
tags: VR, UX
published: 2017-03-07
preview_mp4: /assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-buttons.mp4
preview_webm: /assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-buttons.webm
preview_gif: /assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-buttons.gif
---

My day job consists of creating virtual and augmented reality applications for teaching and learning at my local [University](https://www.ualberta.ca/). In doing this, we run into far more inexperienced users than traditional VR games do. Most of the people using our tools and applications have never experienced virtual reality first hand, and a large percent of them have little to no experience playing video games and thus the expectations and understanding that come from that world. Ultimately, this means that a staggering amount of our target audience has based their entire digital experience expectations on the interactions they've grown accustomed to on their phones and tablets—namely 2D interactions on a 2D screen with 2D objects. Although people inhabit a three-dimensional world, their digital worlds are overwhelmingly two-dimensional, which rapidly becomes a problem in virtual reality where 3D interactions are necessary but often unexpected. As has been well-documented [1](), new VR users are often hesitant to actually move about in a 3D space—when given a headset and controllers, most people stand perfectly still with their hands hovering in front of them until someone or something nudges them along. There are various context clues to do this, such as placing initializing items just out of reach of the player and encouraging / forcing them to take a step forward to reach their goal (or in the case of Valve's [early prototype](https://www.youtube.com/watch?v=BWjP77TztTQ), encouraging to get out of the way of something). Many UX VR articles and practices encourage "physical" interactions, where if a person needs to click a button, they need to reach out and push their controller into that virtual button. And as intuitive as that is in the real world, it simply isn't in the digital one (at least until VR/AR become incorporated into our everyday lives).

In our work, we need to bridge the gap between the 2D interactions and experiences that users expect and the 3D interactions that virtual reality demands. So far I have seen no app do this better than [Tilt Brush](https://www.tiltbrush.com/), and to try to replicate that success and use it in our own products to engage and 


<figure>
    <video autoplay loop>
        <source src="/assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-menu.webm" type="video/webm">
        <source src="/assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-menu.mp4" type="video/mp4">
        <img src="/assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-menu.gif">
    </video>
	<figcaption>The main Tilt Brush menu is inherently 3-dimensional, always attached to the left hand, and always visible.</figcaption>
</figure>

<figure>
    <video autoplay loop>
        <source src="/assets/images/vr-ux-case-study-tilt-brush/backpane-highlighting.webm" type="video/webm">
        <source src="/assets/images/vr-ux-case-study-tilt-brush/backpane-highlighting.mp4" type="video/mp4">
        <img src="/assets/images/vr-ux-case-study-tilt-brush/backpane-highlighting.gif">
    </video>
	<figcaption>As soon as the user points at any point on the menu, the entire panel springs to life: moving forward and increasing in brightness.</figcaption>
</figure>

TODO: gifs of intro tutorial!

<figure>
    <video autoplay loop>
        <source src="/assets/images/vr-ux-case-study-tilt-brush/animated-dashed-pointer.webm" type="video/webm">
        <source src="/assets/images/vr-ux-case-study-tilt-brush/animated-dashed-pointer.mp4" type="video/mp4">
        <img src="/assets/images/vr-ux-case-study-tilt-brush/animated-dashed-pointer.gif">
    </video>
	<figcaption>When one hand gets close to pointing at a panel, a slowly animated dashed line springs forth, giving clear indication of what the user is pointing at.</figcaption>
</figure>

<figure>
    <video autoplay loop>
        <source src="/assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-buttons.webm" type="video/webm">
        <source src="/assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-buttons.mp4" type="video/mp4">
        <img src="/assets/images/vr-ux-case-study-tilt-brush/dimensionality-of-buttons.gif">
    </video>
	<figcaption>Although you don't have to touch the buttons physically, they are still inherently 3D (albeit working different than reality): when a button is highlighting, it lights up and sticks up above the menu.</figcaption>
</figure>

<figure>
    <video autoplay loop>
        <source src="/assets/images/vr-ux-case-study-tilt-brush/colour-hint-on-controller.webm" type="video/webm">
        <source src="/assets/images/vr-ux-case-study-tilt-brush/colour-hint-on-controller.mp4" type="video/mp4">
        <img src="/assets/images/vr-ux-case-study-tilt-brush/colour-hint-on-controller.gif">
    </video>
	<figcaption>Tilt Brush tries to help you know what is about to happen by colouring the lighting on the controller model to match the colour you're about to paint with.</figcaption>
</figure>